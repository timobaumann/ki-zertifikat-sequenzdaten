{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d95cd055-ded9-4aba-a405-a224731b4e9f",
   "metadata": {},
   "source": [
    "# This notebook contains an implementation for language modelling. \n",
    "At the core, a language model is a sequence classifier that uses all the tokens produced so far as input in order to produce a probability density function over all possible next tokens (a token could be a word, a character, or something inbetween). We can then either use the \"best possible guess\" of the classifier as the next token, or we can sample from the distribution according to the distribution. \n",
    "\n",
    "In fact, producing a probability density function comes for free, when we build a neural classifier that uses a softmax output activation. Therefore, nothing actually changes from \"before\", when we simply built classifiers.\n",
    "\n",
    "Once we have trained the model, we repeatedly ask for next tokens, and add these to the context. This is called \"autoregressive sequence generation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccdfcf22-1179-4413-a94c-12846087c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import ipywidgets as widgets\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09659109-f01c-44ca-99a4-8bb11161277b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '#', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xad', '½', 'Ä', 'É', 'Ö', 'Ü', 'ß', 'á', 'ä', 'ç', 'è', 'é', 'ê', 'ï', 'ò', 'ó', 'ô', 'ö', 'ú', 'ü', 'ă', 'ć', 'ę', 'ğ', 'ł', 'ń', 'ō', 'ř', 'ś', 'ž', '̈', '‐', '–', '‘', '’', '‚', '“', '”', '„', '…', '<s>', '</s>']\n",
      "['Liebe Mitbürgerinnen und Mitbürger, jetzt geht es los. Der Anstoß zur Fußball-Weltmeisterschaft steht unmittelbar bevor. Millionen haben auf diesen Augenblick gewartet - nicht nur in Deutschland, sondern in der ganzen Welt.', 'Vor dem Eröffnungsspiel gegen Costa Rica bin ich noch einmal mit Jürgen Klinsmann und unserer Nationalmannschaft zusammengetroffen. Jeder einzelne Spieler ist hochmotiviert und wird - davon bin ich fest überzeugt - sein Bestes geben. Und das sollten auch wir tun. Sie wissen: Die Fans sind der zwölfte Mann auf dem Platz. Wir alle wollen zeigen, dass Deutschland zu Spitzenleistungen fähig ist.', 'Und das nicht nur in den Fußballstadien. Wir freuen uns auf Gäste aus allen Erdteilen und wollen mit ihnen ein großes Fest feiern. Friedlich und fröhlich. Und wir wollen ihnen zeigen, was dieses vielfältige Land zu bieten hat. Sportlich und auch kulturell. Ich freue mich sehr darüber, wie groß das Veranstaltungsangebot in den kommenden vier Wochen ist - weit über die offiziellen Ereignisse hinaus.', 'Das zeigt: Deutschland ist ein weltoffenes, ein modernes und ein lebendiges Land.']\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "\n",
    "START_SYMBOL = \"<s>\"\n",
    "END_SYMBOL = \"</s>\"\n",
    "\n",
    "data = open('data/merkel-de.txt', 'r').read() # should be simple plain text file\n",
    "characters = set(data)\n",
    "characters = list(sorted(characters))\n",
    "characters.append(START_SYMBOL)\n",
    "characters.append(END_SYMBOL)\n",
    "characters.remove('\\n')\n",
    "NUM_CHARACTERS = len(characters)\n",
    "sentences = data.splitlines()\n",
    "int2char = list(characters)\n",
    "char2int = {c:i for i,c in enumerate(characters)}\n",
    "print(characters)\n",
    "print(sentences[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d4a1b19-8640-479a-92ea-28c6fcecc1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = NUM_CHARACTERS\n",
    "EMBED_SIZE = 8\n",
    "HIDDEN_SIZE = 64\n",
    "LAYERS = 2\n",
    "MAX_GENERATION_LENGTH = 80\n",
    "# okay, what's a recurrent neural network anyway? see https://calvinfeng.gitbook.io/machine-learning-notebook/supervised-learning/recurrent-neural-network/recurrent_neural_networks\n",
    "# At every time step, we have an input, \n",
    "\n",
    "NUM_CLASSES = NUM_CHARACTERS\n",
    "class LM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LM, self).__init__()\n",
    "        self.embed = torch.nn.Embedding(INPUT_SIZE, EMBED_SIZE)\n",
    "        torch.nn.init.xavier_uniform_(self.embed.weight)\n",
    "        self.rnn = nn.GRU(EMBED_SIZE, HIDDEN_SIZE, LAYERS)\n",
    "        self.final_layer = nn.Linear(HIDDEN_SIZE, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, xs : torch.tensor):\n",
    "        xs = self.embed(xs)\n",
    "        rnn_outputs, _ = self.rnn(xs)\n",
    "        results = self.final_layer(rnn_outputs)\n",
    "        return results\n",
    "\n",
    "    def forwardx(self, xs : torch.tensor):\n",
    "        xs = self.embed(xs)\n",
    "        h_n = torch.zeros(LAYERS, HIDDEN_SIZE)\n",
    "        #c_n = torch.zeros(LAYERS, HIDDEN_SIZE)\n",
    "        rnn_outputs = []\n",
    "        for x in xs:\n",
    "            x = x[None,:]\n",
    "            rnn_output, h_n = self.rnn(x, h_n)\n",
    "            rnn_outputs.append(rnn_output)\n",
    "        rnn_outputs = torch.cat(rnn_outputs)\n",
    "        results = self.final_layer(rnn_outputs)\n",
    "        return results\n",
    "\n",
    "    def generate(self, xs=torch.tensor([char2int[START_SYMBOL]])) -> torch.tensor:\n",
    "        classification = None\n",
    "        h_n = torch.zeros(LAYERS, HIDDEN_SIZE)\n",
    "        #c_n = torch.zeros(LAYERS, HIDDEN_SIZE)\n",
    "        output = []\n",
    "        xs = self.embed(xs)\n",
    "        while ((classification == None) or (classification.item() != char2int[END_SYMBOL])) and (len(output) < MAX_GENERATION_LENGTH):\n",
    "            rnn_outputs, h_n = self.rnn(xs, h_n)\n",
    "            classification = torch.argmax(self.final_layer(rnn_outputs[-1]), dim=0)\n",
    "            output.append(classification)\n",
    "            xs = self.embed(classification)[None,:]\n",
    "        output = torch.stack(output[:-1]) if len(output) > 0 else torch.tensor([])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fa9d244-e2f1-4f2a-9317-285610cb3654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 starting\n",
      "forced: eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "freeee: eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "Epoch 1 starting\n",
      "forced: ööggcceeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "freeee: ööggcceeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee          nnnnnnnnnnnnnnnnnn\n",
      "Epoch 2 starting\n",
      "forced: Möglccceeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee               \n",
      "freeee: Möglccceeeeeeeeeeeeeeeeeeeeeeeeeeeee                                        nnn\n",
      "Epoch 3 starting\n",
      "forced: Möglicheeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeellllllllll     \n",
      "freeee: Möglicheeeeeeeeeeeeeeeeeeeeeeeeee e e         llll                           nn\n",
      "Epoch 4 starting\n",
      "forced: Möglicheeeeeeeee    eeeeee  eeeee eeeeellllleelllll   \n",
      "freeee: Möglicheeeeeeeeeeee eeeeeeeeee ee e e e e e e e elllll l e e e e e e e e e e e \n",
      "Epoch 5 starting\n",
      "forced: Möglicheeweeee e    eeee e   e  e  eeeellllleellll    \n",
      "freeee: Möglicheeeeeeee ee e e e e e e e e e e e e e e e ellllll el el e el e e e e e e\n",
      "Epoch 6 starting\n",
      "forced: Möglicheeweiie h     See e   e  e  eeeellllleellsl    \n",
      "freeee: Möglicheeeeiiiee h See Se Se e e e e e e e e Fe Fe Felllll ell el e el e e e e \n",
      "Epoch 7 starting\n",
      "forced: Möglicherweise ha e bSie be  e  em Fußßalllpsellsc on \n",
      "freeee: Möglicherweise ha Siee be be bei em Fußßßmmllll sc sa ea ea ea ea ea ea ea ea e\n",
      "Epoch 8 starting\n",
      "forced: Möglicherweise haben Sie bei ei em Fußballlpiel schon \n",
      "freeee: Möglicherweise haben Sie bei ei em Fußballll schon ei echon eineaneaneanaenaena\n",
      "Epoch 9 starting\n",
      "forced: Möglicherweise haben Sie bei ei em Fußballspiel schon \n",
      "freeee: Möglicherweise haben Sie bei ei em Fußballspiel schon einmal etwas von einer Ba\n",
      "Epoch 10 starting\n",
      "forced: Möglicherweise haben Sie bei einem Fußballspiel schon \n",
      "freeee: Möglicherweise haben Sie bei einem Fußballspiel schon einmal etwas von einer Ba\n",
      "Epoch 11 starting\n",
      "forced: Möglicherweise haben Sie bei einem Fußballspiel schon \n",
      "freeee: Möglicherweise haben Sie bei einem Fußballspiel schon einmal etwas von einer Ba\n",
      "Epoch 12 starting\n",
      "forced: Möglicherweise haben Sie bei einem Fußballspiel schon \n",
      "freeee: Möglicherweise haben Sie bei einem Fußballspiel schon einmal etwas von einer Ba\n",
      "Epoch 13 starting\n",
      "forced: Möglicherweise haben Sie bei einem Fußballspiel schon \n",
      "freeee: Möglicherweise haben Sie bei einem Fußballspiel schon einmal etwas von einer Ba\n",
      "Epoch 14 starting\n",
      "forced: Möglicherweise haben Sie bei einem Fußballspiel schon \n",
      "freeee: Möglicherweise haben Sie bei einem Fußballspiel schon einmal etwas von einer Ba\n",
      "Epoch 15 starting\n",
      "forced: Möglicherweise haben Sie bei einem Fußballspiel schon \n",
      "freeee: Möglicherweise haben Sie bei einem Fußballspiel schon einmal etwas von einer Ba\n",
      "Epoch 16 starting\n",
      "forced: Möglicherweise haben Sie bei einem Fußballspiel schon \n",
      "freeee: Möglicherweise haben Sie bei einem Fußballspiel schon einmal etwas von einer Ba\n",
      "Epoch 17 starting\n",
      "forced: Möglicherweise haben Sie bei einem Fußballspiel schon \n",
      "freeee: Möglicherweise haben Sie bei einem Fußballspiel schon einmal etwas von einer Ba\n",
      "Epoch 18 starting\n",
      "forced: Möglicherweise haben Sie bei einem Fußballspiel schon \n",
      "freeee: Möglicherweise haben Sie bei einem Fußballspiel schon einmal etwas von einer Ba\n",
      "Epoch 19 starting\n",
      "forced: Möglicherweise haben Sie bei einem Fußballspiel schon \n",
      "freeee: Möglicherweise haben Sie bei einem Fußballspiel schon einmal etwas von einer Ba\n",
      "M\n"
     ]
    }
   ],
   "source": [
    "#training_data = [\"hello\"] * 50\n",
    "#training_data = [\"abcdefghijklmnopqrstuvwxyz\"] * 30\n",
    "training_data = [\"Möglicherweise haben Sie bei einem Fußballspiel schon einmal etwas von einer Bananenflanke gehört.\"] * 100\n",
    "#training_data = sentences * 5\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "def to_vector(sentence : str, noend=False) -> torch.tensor:\n",
    "    sentence = [START_SYMBOL] + list(sentence)\n",
    "    if not noend:\n",
    "        sentence.append(END_SYMBOL)\n",
    "    return torch.tensor([char2int[c] for c in sentence])\n",
    "\n",
    "lm = LM()\n",
    "optimizer = torch.optim.Adam(lm.parameters())\n",
    "\n",
    "def training(training_data, validation_data=[]):\n",
    "    training_data = [to_vector(s) for s in training_data]\n",
    "    validation_data = [to_vector(s) for s in validation_data]\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        print((\"Epoch {} starting\".format(epoch)))\n",
    "        #random.shuffle(training_data)\n",
    "        for s in training_data:\n",
    "            optimizer.zero_grad()\n",
    "            all_input = s[:-1]\n",
    "            all_predictions = s[1:]\n",
    "            outputs = lm(all_input)\n",
    "            losses = nn.functional.cross_entropy(outputs, all_predictions)\n",
    "            loss = torch.sum(losses)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"forced: \" + \"\".join([int2char[x] for x in torch.argmax(lm(to_vector(\"Möglicherweise haben Sie bei einem Fußballspiel schon\", True)), dim=1)]))\n",
    "        print(\"freeee: \" + \"\".join([int2char[x] for x in lm.generate()]))\n",
    "    return lm\n",
    "\n",
    "\n",
    "lm = training(training_data)\n",
    "result = lm(to_vector(\"\", True))\n",
    "#result = torch.topk(result, 3, dim=1)\n",
    "print(\"\".join([int2char[x] for x in torch.argmax(result, dim=1)]))\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "79e103d9-9b3c-4afa-b6bb-5308cffae630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allspiel eier einerwas einerwas einerwas einerwas einerwas einerwas einerwas ei\n"
     ]
    }
   ],
   "source": [
    "#print(\"\".join([int2char[x] for x in lm.generate()]))\n",
    "print(\"\".join([int2char[x] for x in lm.generate(to_vector(\"Möglicherweise haben Sie bei einem Fuß\", True))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "93be17d5-52b8-442f-93f5-2814be310869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2char[47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2113f-d0ef-421b-9366-0be50443a0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
