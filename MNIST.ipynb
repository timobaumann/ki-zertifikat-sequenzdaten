{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72da59d8-ad65-442d-80ea-5cb3703810c5",
   "metadata": {},
   "source": [
    "# Timo's attempts at an MNIST classifier\n",
    "My goal here is twofold: \n",
    " * try to simply copy-paste my pre-existing (DyNet-based) MNIST code and log minimal adaptations necessary\n",
    " * adapt the code to make it more torchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f03eafa-9028-41f2-86b4-2778ee556462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import ipywidgets as widgets\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918099da-113d-411e-8cc9-bdcadd5709f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "# we will often repeatedly use some code for plotting. We define this once to be re-used later.\n",
    "def plot(plot_data):\n",
    "    plt.figure(\"evolution over training iterations\")\n",
    "    for type in plot_data.keys():\n",
    "       plt.plot(plot_data[type], label=type)\n",
    "    plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77bafc86-06d9-4dfd-aeb5-19eaec5517a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimally adapted from https://gist.github.com/akesling/5358964\n",
    "def read_mnist(dataset, path=\"data/MNIST/raw/\"):\n",
    "    if dataset == \"training\":\n",
    "        fname_img = os.path.join(path, \"train-images-idx3-ubyte\")\n",
    "        fname_lbl = os.path.join(path, \"train-labels-idx1-ubyte\")\n",
    "    elif dataset == \"testing\":\n",
    "        fname_img = os.path.join(path, \"t10k-images-idx3-ubyte\")\n",
    "        fname_lbl = os.path.join(path, \"t10k-labels-idx1-ubyte\")\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, \"rb\") as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        labels = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, \"rb\") as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        images = np.multiply(\n",
    "            np.fromfile(fimg, dtype=np.uint8).reshape(len(labels), rows*cols),\n",
    "            1.0 / 255.0)\n",
    "\n",
    "    get_instance = lambda idx: (labels[idx], images[idx])\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in range(len(labels)):\n",
    "        yield get_instance(i)\n",
    "        \n",
    "training = [(lbl, img) for (lbl, img) in read_mnist(\"training\")]\n",
    "testing = [(lbl, img) for (lbl, img) in read_mnist(\"testing\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31190f92-5493-4147-846c-62cb796efffb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecc398e2fb74aee9588d2d2d39d82e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991f647480ec41a59b796714401413ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d2f7f9419d45eba277fec25417f3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc515a9aab8a45c7a6f9dc1377bf8190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ef42080ffe453498797e8ca8de24b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8261d90cecab478a929c823d72b5ee83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526d0b82b8614549bd785aa5deb6a355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32176b6a13f74cd9886e70b43d98b6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec78f75e10d487d838f3a74f9c87010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1daf40d0127049dc92b00622c034bf12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "# print some examples (pairs of target number and image)\n",
    "for i in range(10):\n",
    "    buffer = io.BytesIO()\n",
    "    PIL.Image.fromarray((256*training[i][1]).reshape(28, 28)).convert('L').save(buffer, format=\"PNG\")\n",
    "    display(training[i][0], widgets.Image(value=buffer.getvalue(),width=28,height=28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9324f8c-d313-42b1-b665-07ddb93615f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM1 = 64\n",
    "HIDDEN_DIM2 = 64\n",
    "DROPOUT_RATE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64108ce7-553f-4ece-be83-1c4102938f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassify(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassify, self).__init__()\n",
    "        input_size = 28 * 28\n",
    "        self.W1 = nn.Parameter(nn.init.xavier_uniform_(torch.empty(input_size, HIDDEN_DIM1)))\n",
    "        self.b1 = nn.Parameter(nn.init.xavier_uniform_(torch.empty(1, HIDDEN_DIM1)))\n",
    "        self.W2 = nn.Parameter(nn.init.xavier_uniform_(torch.empty(HIDDEN_DIM1, HIDDEN_DIM2)))\n",
    "        self.b2 = nn.Parameter(nn.init.xavier_uniform_(torch.empty(1, HIDDEN_DIM2)))\n",
    "        self.W3 = nn.Parameter(nn.init.xavier_uniform_(torch.empty(HIDDEN_DIM2, 10)))\n",
    "        self.b3 = nn.Parameter(nn.init.xavier_uniform_(torch.empty(1, 10)))\n",
    "        \n",
    "    def forward(self, x, isTrain=False):\n",
    "        # erste innere Schicht:\n",
    "        h1 = nn.functional.sigmoid(x @ self.W1 + self.b1)\n",
    "        # zweite innere Schicht:\n",
    "        h2 = nn.functional.sigmoid(h1 @ self.W2 + self.b2)\n",
    "        # Ergebnisschicht:\n",
    "        activation = nn.functional.sigmoid(h2 @ self.W3 + self.b3, dim=1)\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52dfe965-5466-4000-965b-6893eea70987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassify(nn.Module):\n",
    "    \"\"\"probably a more torchy version, considerably easier than the DyNet version.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(MNISTClassify, self).__init__()\n",
    "        input_size = 28 * 28\n",
    "        self.l1 = nn.Linear(input_size, HIDDEN_DIM1)\n",
    "        self.l2 = nn.Linear(HIDDEN_DIM1, HIDDEN_DIM2)\n",
    "        self.l3 = nn.Linear(HIDDEN_DIM2, 10)\n",
    "\n",
    "    def forward(self, x, isTrain=False):\n",
    "        return nn.functional.log_softmax(self.l3(nn.functional.sigmoid(self.l2(nn.functional.sigmoid(self.l1(x))))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79bee91c-0c24-4b13-bc26-06c5e6df3629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class MNISTClassify(nn.Module):\n",
    "    \"\"\"works much better with CNNs.\n",
    "    shamefully stolen/borrowed from https://github.com/mbjoseph/pytorch-mnist/blob/master/cnn-mnist.ipynb\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MNISTClassify, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 120)\n",
    "        self.fc1_drop = nn.Dropout()\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "        \n",
    "    def forward(self, x, isTrain=False):\n",
    "        x = x.reshape((1,1,28,28))\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1_drop(self.fc1(x)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(x)\n",
    "        return x.view((10))\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51d2157b-9860-4162-9261-4752a6ae0a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_200020/245547631.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Held out accuracy 0.3697 (2020.0007965758605 instances/sec)\n",
      "   T0    T1    T2    T3    T4    T5    T6    T7    T8    T9    \n",
      "P0 959   8     14    8     2     9     23    10    19    11    \n",
      "P1 0     0     0     0     0     0     0     0     0     0     \n",
      "P2 0     0     0     0     0     0     0     0     0     0     \n",
      "P3 0     0     0     0     0     0     0     0     0     0     \n",
      "P4 2     11    12    4     957   9     17    3     25    44    \n",
      "P5 0     0     0     0     0     0     0     0     0     0     \n",
      "P6 0     0     0     0     0     0     0     0     0     0     \n",
      "P7 0     0     0     0     0     0     2     0     0     0     \n",
      "P8 13    1110  1004  988   16    851   913   998   882   55    \n",
      "P9 6     6     2     10    7     23    3     17    48    899   \n",
      "instances per sec: 197.01721691919752\n",
      "Epoch 2 starting\n",
      "Held out accuracy 0.4639 (2269.8473181024306 instances/sec)\n",
      "   T0    T1    T2    T3    T4    T5    T6    T7    T8    T9    \n",
      "P0 956   10    12    1     1     16    10    9     36    9     \n",
      "P1 0     0     0     0     0     0     0     0     0     0     \n",
      "P2 0     0     0     0     0     0     0     0     0     0     \n",
      "P3 0     0     0     0     0     0     0     0     0     0     \n",
      "P4 4     14    4     1     948   6     1     4     13    17    \n",
      "P5 0     0     0     0     0     1     0     0     0     0     \n",
      "P6 9     10    5     1     7     29    928   1     28    1     \n",
      "P7 0     0     0     0     0     0     0     0     0     0     \n",
      "P8 8     1098  1008  989   12    817   19    988   859   35    \n",
      "P9 3     3     3     18    14    23    0     26    38    947   \n",
      "instances per sec: 216.429940155843\n",
      "Epoch 3 starting\n",
      "Held out accuracy 0.5618 (2323.8209845660494 instances/sec)\n",
      "   T0    T1    T2    T3    T4    T5    T6    T7    T8    T9    \n",
      "P0 956   9     8     2     1     14    10    0     20    4     \n",
      "P1 0     0     0     0     0     0     0     0     0     0     \n",
      "P2 0     0     0     0     0     0     0     0     0     0     \n",
      "P3 0     0     0     0     0     0     0     0     0     0     \n",
      "P4 2     17    9     6     945   16    5     2     13    13    \n",
      "P5 0     0     0     0     0     1     0     0     0     0     \n",
      "P6 6     6     1     1     8     15    921   0     5     1     \n",
      "P7 5     15    53    27    1     25    0     957   20    18    \n",
      "P8 9     1085  959   957   9     790   22    46    886   21    \n",
      "P9 2     3     2     17    18    31    0     23    30    952   \n",
      "instances per sec: 226.74641749560107\n",
      "Epoch 4 starting\n",
      "Held out accuracy 0.5604 (2245.3627839623978 instances/sec)\n",
      "   T0    T1    T2    T3    T4    T5    T6    T7    T8    T9    \n",
      "P0 942   6     8     3     1     5     9     2     15    3     \n",
      "P1 0     0     0     0     0     0     0     0     0     0     \n",
      "P2 0     0     0     0     0     0     0     0     0     0     \n",
      "P3 0     0     0     0     0     0     0     0     0     0     \n",
      "P4 1     3     6     2     943   5     4     2     14    31    \n",
      "P5 0     0     0     0     0     0     0     0     0     0     \n",
      "P6 17    11    11    2     10    23    934   1     32    2     \n",
      "P7 4     21    42    12    1     9     0     974   14    12    \n",
      "P8 12    1093  963   987   14    836   11    37    882   32    \n",
      "P9 4     1     2     4     13    14    0     12    17    929   \n",
      "instances per sec: 232.06130336224072\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classify = MNISTClassify().float()\n",
    "learning_rate = 0.01\n",
    "#optimizer = torch.optim.SGD(classify.parameters(), lr = learning_rate)\n",
    "optimizer = torch.optim.Adam(classify.parameters())\n",
    "#loss = nn.CrossEntropyLoss\n",
    "dev_time = 0\n",
    "plot_data = defaultdict(lambda : [])\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1,5):\n",
    "    print((\"Epoch {} starting\".format(epoch)))\n",
    "    random.shuffle(training)\n",
    "    # train model:\n",
    "    for cls, img in training:\n",
    "        optimizer.zero_grad()\n",
    "        # Bild als Eingabe aufbereiten\n",
    "        x = torch.tensor(img).float()\n",
    "        # Outputaktivierung berechnen\n",
    "        output = classify(x, isTrain=True)\n",
    "        # \"idealen\" Output (überall 0, nur gewählte Klasse ist 1)\n",
    "        target = torch.zeros(10).long()\n",
    "        target[cls] = 1.0\n",
    "        # Kostenfunktion berechnen\n",
    "        #loss = torch.sum((output - target) ** 2)\n",
    "        loss  = nn.functional.nll_loss(output, torch.tensor(cls).long())\n",
    "        # Kosten den einzelnen Parametern zuordnen\n",
    "        plot_data[\"error\"].append(loss.item())\n",
    "        loss.backward()\n",
    "        # Parameter entsprechend anpassen\n",
    "        optimizer.step()\n",
    "\n",
    "    # test performance of classifier:\n",
    "    confusion = [[0 for _ in range(10)] for _ in range(10)]\n",
    "    correct = 0\n",
    "    dev_start = time.time()\n",
    "    for cls, img in testing:\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(img).float()\n",
    "        output = classify(x, isTrain=False)\n",
    "        prediction = int(torch.topk(output, 1)[1].item())\n",
    "        if cls == prediction:\n",
    "            correct += 1\n",
    "        confusion[prediction][cls] += 1\n",
    "    dev_end = time.time()\n",
    "    acc = float(correct) / len(testing)\n",
    "    dev_time += dev_end - dev_start\n",
    "    print((\"Held out accuracy {} ({} instances/sec)\".format(\n",
    "        acc, len(testing) / (dev_end - dev_start))))\n",
    "    print('   ' + ''.join(('T'+str(x)).ljust(6) for x in range(10)))\n",
    "    for p, row in enumerate(confusion):\n",
    "        s = 'P' + str(p) + ' '\n",
    "        s += ''.join(str(col).ljust(6) for col in row)\n",
    "        print(s)\n",
    "\n",
    "    end = time.time()\n",
    "    print((\"instances per sec: {}\".format(\n",
    "                (epoch * len(training)) / (end - start - dev_time))))\n",
    "\n",
    "plot(plot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8f2fd5-c72a-4816-9b9f-4b46eb844b4d",
   "metadata": {},
   "source": [
    "Notes on differences between DyNet and PyTorch: \n",
    "* in DyNet, I register parameters without specifying the tensor that will be used for it; it will be automatically assigned.\n",
    "    * In PyTorch, I register a specific tensor. Smart as I am, I didn't assign a zeros-tensor -- instead I have to ponder about parameter initialization.\n",
    "    * It turns out that DyNet uses Glorot/Xavier initialization and some aspect of it depends on the following non-linearity. (wow!)\n",
    "    * I'll (roughly) replace with what DyNet does → yields pretty much identical results\n",
    "* instead of `*` for matrix multiplication, one has to write `@`. Okay.\n",
    "* Something that I did not quite understand about float() and double() with tensors.\n",
    "* DyNet is 5 times faster than PyTorch, wow! (I wonder what is causing this.)\n",
    "    * it's not the manually defined loss function\n",
    "    * it's not the use of parameters myself over using nn.Linear layers (which is still a little slower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf63709-76c2-4fbe-9e8e-800f890b0ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[dynet] random seed: 1054449114\n",
      "[dynet] allocating memory: 512MB\n",
      "[dynet] memory allocation done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 starting\n",
      "Held out accuracy 0.95 (13516.539965002627 instances/sec)\n",
      "   T0    T1    T2    T3    T4    T5    T6    T7    T8    T9    \n",
      "P0 970   0     10    1     3     11    15    2     5     9     \n",
      "P1 0     1114  2     0     0     0     3     7     1     6     \n",
      "P2 2     4     990   15    3     2     1     13    5     1     \n",
      "P3 1     3     4     947   0     18    1     2     13    7     \n",
      "P4 0     0     3     1     946   1     2     1     3     42    \n",
      "P5 3     1     0     10    0     825   6     1     7     14    \n",
      "P6 1     5     6     0     8     7     922   0     7     0     \n",
      "P7 2     2     9     15    7     3     1     1001  11    49    \n",
      "P8 1     6     8     20    4     23    7     0     922   18    \n",
      "P9 0     0     0     1     11    2     0     1     0     863   \n",
      "instances per sec: 8257.331566533325\n",
      "Epoch 2 starting\n",
      "Held out accuracy 0.9621 (13458.776899558723 instances/sec)\n",
      "   T0    T1    T2    T3    T4    T5    T6    T7    T8    T9    \n",
      "P0 969   0     6     1     1     4     9     1     5     1     \n",
      "P1 0     1105  0     0     1     1     2     4     1     4     \n",
      "P2 2     5     1007  16    4     3     5     12    5     2     \n",
      "P3 1     3     2     964   0     8     0     2     11    6     \n",
      "P4 0     0     1     2     950   0     5     2     3     24    \n",
      "P5 2     2     0     10    0     855   6     2     9     12    \n",
      "P6 4     1     3     0     6     5     923   0     3     2     \n",
      "P7 1     6     8     8     3     0     1     993   11    17    \n",
      "P8 1     13    5     9     4     13    7     1     922   8     \n",
      "P9 0     0     0     0     13    3     0     11    4     933   \n",
      "instances per sec: 8220.989827360456\n",
      "Epoch 3 starting\n",
      "Held out accuracy 0.9669 (13351.766816229147 instances/sec)\n",
      "   T0    T1    T2    T3    T4    T5    T6    T7    T8    T9    \n",
      "P0 965   0     5     0     2     3     6     2     3     2     \n",
      "P1 0     1122  2     0     2     1     3     6     1     10    \n",
      "P2 2     1     995   4     2     1     1     9     2     0     \n",
      "P3 2     3     7     971   1     10    1     5     6     7     \n",
      "P4 0     0     3     1     952   2     2     3     4     27    \n",
      "P5 2     2     1     5     1     852   4     2     6     5     \n",
      "P6 3     1     3     0     7     9     933   0     1     1     \n",
      "P7 2     1     7     10    4     1     1     997   3     12    \n",
      "P8 4     5     8     17    6     11    7     0     947   10    \n",
      "P9 0     0     1     2     5     2     0     4     1     935   \n",
      "instances per sec: 8212.925582626229\n",
      "Epoch 4 starting\n",
      "Held out accuracy 0.9649 (13447.38091642677 instances/sec)\n",
      "   T0    T1    T2    T3    T4    T5    T6    T7    T8    T9    \n",
      "P0 966   0     7     0     2     4     4     2     5     4     \n",
      "P1 0     1124  1     0     0     1     2     5     2     5     \n",
      "P2 2     3     1012  8     4     1     2     20    3     1     \n",
      "P3 4     2     3     988   1     24    1     6     11    13    \n",
      "P4 0     0     0     0     909   2     0     1     4     5     \n",
      "P5 0     1     0     1     0     844   4     0     6     6     \n",
      "P6 5     4     3     0     15    9     943   0     7     2     \n",
      "P7 1     0     3     6     5     2     0     971   3     5     \n",
      "P8 2     1     2     6     7     3     2     0     932   8     \n",
      "P9 0     0     1     1     39    2     0     23    1     960   \n",
      "instances per sec: 8203.387139847362\n"
     ]
    }
   ],
   "source": [
    "import dynet as dy\n",
    "dy.sigmoid = dy.logistic\n",
    "\n",
    "class MNISTClassify(object):\n",
    "    def __init__(self, m):\n",
    "        input_size = 28 * 28\n",
    "        self.W1 = m.add_parameters((HIDDEN_DIM1, input_size))\n",
    "        self.b1 = m.add_parameters((HIDDEN_DIM1, ))\n",
    "        self.W2 = m.add_parameters((HIDDEN_DIM2, HIDDEN_DIM1))\n",
    "        self.b2 = m.add_parameters((HIDDEN_DIM2, ))\n",
    "        self.W3 = m.add_parameters((10, HIDDEN_DIM2))\n",
    "        self.b3 = m.add_parameters((10, ))\n",
    "\n",
    "    def __call__(self, x, isTrain=False):\n",
    "        # erste innere Schicht:\n",
    "        h1 = dy.sigmoid(self.W1 * x + self.b1)\n",
    "        # zweite innere Schicht:\n",
    "        h2 = dy.sigmoid(self.W2 * h1 + self.b2)\n",
    "        # Ergebnisschicht:\n",
    "        activation = dy.sigmoid(self.W3 * h2 + self.b3)\n",
    "        return activation\n",
    "\n",
    "m = dy.Model()\n",
    "classify = MNISTClassify(m)\n",
    "#sgd = dy.SimpleSGDTrainer(m, learning_rate=0.01)\n",
    "sgd = dy.AdamTrainer(m)\n",
    "dev_time = 0\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1,5):\n",
    "    random.shuffle(training)\n",
    "    print((\"Epoch {} starting\".format(epoch)))\n",
    "    # train model:\n",
    "    for cls, img in training:\n",
    "        dy.renew_cg()\n",
    "        # Bild als Eingabe aufbereiten\n",
    "        x = dy.inputVector(img)\n",
    "        # Outputaktivierung berechnen\n",
    "        output = classify(x, isTrain=True)\n",
    "        # \"idealen\" Output (überall 0, nur gewählte Klasse ist 1)\n",
    "        target = np.zeros(10)\n",
    "        target[cls] = 1\n",
    "        target = dy.inputVector(target)\n",
    "        # Kostenfunktion berechnen\n",
    "        loss = 0.5 * dy.sum_elems((output - target) ** 2)\n",
    "        # Kosten den einzelnen Parametern zuordnen\n",
    "        loss.backward()\n",
    "        # Parameter entsprechend anpassen\n",
    "        sgd.update()\n",
    "\n",
    "    # test performance of classifier:\n",
    "    confusion = [[0 for _ in range(10)] for _ in range(10)]\n",
    "    correct = 0\n",
    "    dev_start = time.time()\n",
    "    for cls, img in testing:\n",
    "        dy.renew_cg()\n",
    "        x = dy.inputVector(img)\n",
    "        output = classify(x, isTrain=False)\n",
    "        prediction = max([(v,i) for (i,v) in enumerate(output.value())])[1]\n",
    "        if cls == prediction:\n",
    "            correct += 1\n",
    "        confusion[prediction][cls] += 1\n",
    "    dev_end = time.time()\n",
    "    acc = float(correct) / len(testing)\n",
    "    dev_time += dev_end - dev_start\n",
    "    print((\"Held out accuracy {} ({} instances/sec)\".format(\n",
    "        acc, len(testing) / (dev_end - dev_start))))\n",
    "    print('   ' + ''.join(('T'+str(x)).ljust(6) for x in range(10)))\n",
    "    for p, row in enumerate(confusion):\n",
    "        s = 'P' + str(p) + ' '\n",
    "        s += ''.join(str(col).ljust(6) for col in row)\n",
    "        print(s)\n",
    "\n",
    "    end = time.time()\n",
    "    print((\"instances per sec: {}\".format(\n",
    "                (epoch * len(training)) / (end - start - dev_time))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949e6e6-aed5-4536-bfae-b142e654e120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
